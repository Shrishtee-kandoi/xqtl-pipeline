{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "therapeutic-assist",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Phenotype data formatting\n",
    "\n",
    "\n",
    "This module implements a collection of workflows used to format molecular phenotype data.\n",
    "\n",
    "\n",
    "\n",
    "## Input\n",
    "The input for this workflow is the collection of data for 1 conditions as described in the readme of this git repo\n",
    "1. 1 complete residual molecular_phenotype data\n",
    "2. 1 region_list\n",
    "Both of these input can be generated by the annotation module of this pipeline\n",
    "\n",
    "## Output\n",
    "For each collection, the output is \n",
    "1. 1 lists of phenotype file (bed+index) for each chrom, suitable to be fed into both apex and tensorQTL, annotated with chrom and pos\n",
    "2. 1 lists of phenotype file (bed+index) for each gene, annotated with chrom and tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-championship",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    " sos run /home/hs3163/GIT/xqtl-pipeline/pipeline/data_preprocessing/phenotype/phenotype_formatting.ipynb reformat \\\n",
    "--region_list /home/hs3163/GIT/ADSPFG-xQTL/MWE/mwe_region_long \\\n",
    "--phenoFile /mnt/mfs/statgen/xqtl_workflow_testing/success_example/testing_10/Data_Processing/Phenotype/AC.mol_phe.bed  \\\n",
    "--cwd ./  \\\n",
    "--name \"Dry\" --container \"/mnt/mfs/statgen/containers/apex.sif\" &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equal-silence",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "import os\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path\n",
    "# The filename namefor output data\n",
    "parameter: container = 'gaow/twas'\n",
    "# An index text file with 5 columns specifying the chr, start, end and names of regions to analyze\n",
    "parameter: region_list = path\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "# Path to the input molecular phenotype data.\n",
    "parameter: phenoFile = path\n",
    "# name for the analysis output\n",
    "parameter: name= f'{phenoFile:bn}'\n",
    "parameter: pop_file = \"None\"\n",
    "regions = [x.strip().split() for x in open(region_list).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "# Get the unique chormosome that have regions to be analyzed.\n",
    "def extract(lst):\n",
    "    return [item[0] for item in lst]\n",
    "chrom = list(set(extract(regions)))\n",
    "# Whether the input data is named by gene_id or gene_name. By default it is gene_id, if not, please change it to gene_name\n",
    "parameter: gene_name_as_phenotype_id = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df0a8a6-a874-4c02-b007-142d96b860fe",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Region List generation\n",
    "\n",
    "To partitioning the data by genes require a region list file which:\n",
    "\n",
    "    1. have 5 columns: chr,start,end,gene_id,gene_name\n",
    "    2. have the same gene as or less gene than that of the bed file\n",
    "    \n",
    "Input:\n",
    "\n",
    "    1. A gtf file used to generated the bed\n",
    "    2. A phenotype bed file, must have a gene_id column indicating the name of genes.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5913f0bd-a40e-45ff-a5d1-77b99b5752dd",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[generate_region_list]\n",
    "#  gene gtf annotation table\n",
    "parameter: annotation_gtf = path\n",
    "input: phenoFile, annotation_gtf\n",
    "output: f'{cwd:a}/{_input[0]:bnn}.region_list'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "python: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container\n",
    "    import pandas as pd\n",
    "    import qtl.io\n",
    "    # get the five column data\n",
    "    bed_template_df_id = qtl.io.gtf_to_tss_bed(${_input[1]:ar}, feature='transcript',phenotype_id = \"gene_id\" )\n",
    "    bed_template_df_name = qtl.io.gtf_to_tss_bed(${_input[1]:ar}, feature='transcript',phenotype_id = \"gene_name\" )\n",
    "    bed_template_df = bed_template_df_id.merge(bed_template_df_name, on = [\"chr\",\"start\",\"end\"])\n",
    "    # retaining only somatic chromosome\n",
    "    bed_template_df = bed_template_df[bed_template_df.chr.isin([\"chr\" + str(x) for x in (range(1,23))])]\n",
    "    bed_template_df.columns = [\"#chr\",\"start\",\"end\",\"gene_id\",\"gene_name\"]\n",
    "    pheno = pd.read_csv(${_input[0]:r}, sep = \"\\t\")\n",
    "    # Retaining only the genes in the data\n",
    "    region_list = bed_template_df[bed_template_df.${phenotype_id_type}.isin(pheno.gene_id)]\n",
    "    region_list.to_csv(\"${_output}\", sep = \"\\t\",index = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-summit",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Process of molecular phenotype file\n",
    "This workflow produce a bed+tabix file for all the molecular pheno data that are included in the region list to feed into downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-tobacco",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[reformat_1,partition_by_chrom_1]\n",
    "# Path to the input molecular phenotype data.\n",
    "input: phenoFile ,for_each = \"chrom\"\n",
    "output: f'{cwd:a}/{name}.{_chrom}.mol_phe.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    zcat $[_input] | head -1 > $[_output:n]\n",
    "    tabix $[_input] $[_chrom] >> $[_output:n] \n",
    "    bgzip -f $[_output:n]\n",
    "    tabix -p bed $[_output] -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-number",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[reformat_2,partition_by_chrom_2]\n",
    "# Path to the input molecular phenotype data.\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd:a}/{name}.processed_phenotype.per_chrom.recipe'\n",
    "import pandas as pd\n",
    "chrom_df = pd.DataFrame({\"#id\" : chrom ,\"#dir\" : _input})\n",
    "chrom_df.to_csv(_output,index = 0,sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-electronics",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-pollution",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_gene_1]\n",
    "# Path to the input molecular phenotype data.\n",
    "input: phenoFile ,for_each = \"regions\"\n",
    "output: f'{cwd:a}/{name}.{_regions[3]}.{_regions[4]}.mol_phe.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "bash: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container\n",
    "    zcat $[_input] | head -1 > $[_output:n]\n",
    "    zcat $[_input] | grep  $[_regions[3] if gene_name_as_phenotype_id else _regions[4]] >> $[_output:n]\n",
    "    bgzip -f $[_output:n]\n",
    "    tabix -p bed $[_output] -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-abraham",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[partition_by_gene_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd:a}/{name}.processed_phenotype.per_gene.recipe'\n",
    "import pandas as pd\n",
    "region_df = pd.DataFrame({\"#id\" : [x[3] for x in regions] ,\"dir\" : _input})\n",
    "region_df.to_csv(_output,index = 0,sep = \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
